<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="styles.css">
  <script src="./index.js" defer></script>
  <title>Document</title>
</head>
<body>
  <header>
    <h1>Relatório Trabalho 1 de Redes II</h1>
    <p>Eduardo Vudala</p>
    <p>Gabriel Lüders</p>
    <a href="https://github.com/ludersGabriel/udp-canon">repositório</a>
  </header>
  <section>
    <div>
      <h2>1. Introdução</h2>
      <p>
        Este relatório tem como objetivo apresentar o trabalho realizado na disciplina de Redes II, 
        ministrada pelo professor Elias P. Duarte Jr., no semestre 2022/2.
      </p>
      <p>
        <br>
        O trabalho consiste em implementar um canhão UDP com o intuito de medir a taxa aproximada
        de perda de pacote em uma rede, além de verificar se mensagens são entregues fora de ordem.
      </p>
    </div>
    <div>
      <h2>2. Implementação</h2>
      <p>
        O trabalho foi implementado em C++ e consiste em bibliotecas para o cliente, servidor e
        o tipo de mensagem sendo transmitida, além de duas mains, uma para o cliente e outra
        para o servidor, que utilizam a API de sockets do C++ para comunicar datagramas UDP.
        <br><br>
        Para compilar o trabalho basta executar "make" no diretório raíz do projeto. Instruções 
        sobre como rodar cliente e servidor estão descritas abaixo. Vale a pena ressaltar que 
        o servidor deve ser executado antes do cliente.
      </p>

      <h3>2.1. Mensagem</h3>
      <p>
        A mensagem é uma struct composta por um ID de mensagem, um ID de cliente (que é basicamente
        o PID do processo enviando aquele datagrama) e uma string de 100 caracteres:
      </p>

      <div class="imgWrapper">
        <img src="images/message.png" alt="estrutura das mensagens">
      </div>

      <p>
        As mensagens são enviadas em um datagrama UDP via função sendto e recebidas pela função
        recvfrom da API de sockets do C++. 
      </p>
      
      <h3>2.2. Cliente</h3>
      <p>
        O cliente é composto por um gerenciador responsável por controlar uma série de clientes filhos,
        gerados via fork, que são responsáveis por enviar mensagens para o servidor. 
        Cada filho envia o mesmo número de mensagens ao servidor, com IDs de mensagem sequenciais
        - de 1 até o número máximo enviado por cada um -, de maneira concorrente.
      </p>
      <p>
        <br>
        Cada fork é dado por uma estrutura constituida por um descritor de socket por onde realizar
        a comunicação com o servidor, o endereço do servidor, uma entendidade de host, 
        uma string que representa o nome do servidor e uma main responsável pela comunicação:
      </p>
      
      <div class="imgWrapper">
        <img src="images/client.png" alt="estutura do cliente">
      </div>
      
      <p>
        Ao passo que o gerenciador é uma main própria responsável por gerar os filhos e 
        imprimir os relatórios após todos os filhos terminarem de rodar.
        <br><br>
      </p>

      <h4>2.2.1 Rodando o cliente</h4>
      <p>
        <br>
        Para rodar o cliente, basta executar ./client &lt;server&gt; &lt;porta&gt; 
        &lt;quantidade de clientes&gt; &lt;quantidade de mensagens por cliente&gt; 
        [path-to-output]. O parâmetro path-to-output não é obrigatório e tem valor default = stdout.
      </p>
      
      <h3>2.3. Servidor</h3>
      <p>
        O servidor é um servidor UDP comum que recebe mensagens da forma apresentada acima, 
        trata essas mensagens, responde cada uma e, após um timeout de 5 segundos, imprime
        os relatórios de mensagens recebidas, perdidas e fora de ordem.
      </p>

      <p>
        <br>
        A estrutura do servidor é dada por um descritor de socket, um buffer para a mensagem
        recebida, o endereço do servidor, o endereço do cliente, uma entidade de host, uma string
        que representa o nome do servidor, um booleano que indica se o servidor deve imprimir 
        mensagens na tela, o total de clientes conversando, o total de mensagens esperadas, o total
        de mensagens perdidas e o total de mensagens fora de ordem. Além disso, também
        possui uma esturtura que representa as informações das mensagens para tratamento 
        e produção de relatórios e um booleano que indica que o alarme do timeout foi disparado:
      </p>

      <div class="serverImages">
        <div class="imgWrapper">
          <img src="images/server.png" alt="estutura do servidor">
        </div>
        <div>
          <img src="images/reportInfo.png" alt="estutura do relatório">
        </div>
      </div>

      <h4>2.3.1 Rodando o servidor</h4>
      <p>
        <br>
        Para rodar o servidor, basta executar ./server &lt;porta&gt; [path-to-output].
        O parâmetro path-to-output não é obrigatório e tem valor default = stdout.
      </p>

      <h3>2.4. Comunicação</h3>
      <p>
        Inicialmente, o gerenciador e o servidor realizam um handshake no qual a quantidade de 
        clientes a serem abertos e a quantidade de mensagens por cliente são enviadas ao servidor.
        Após, o gerente faz o fork de todos os clientes que iniciam comunicação com o servidor 
        imediamente.
        <br><br>
        Cada cliente envia X mensagens para o servidor com um ID de mensagem sequencial, 
        incrementado um a um. O servidor recebe as mensagens, trata e responde cada uma. Os clientes,
        contudo, não esperam as respostas do servidor para enviar a próxima mensagem. Portanto, a 
        resposta que o servidor realiza é apenas para simular o load de uma comunicação real, além
        dos processamentos já feitos.
      </p>
      <p>
        <br>
        Quando todos os clientes terminam de enviar suas mensagens, o servidor finaliza o 
        loop de escuta após um timeout de 5 segundos. Em seguida, imprime os relatórios e 
        escreve os arquivos utilizados para tratamentos finais e geração de gráficos. 
      </p>
      <p>
        <br>
        No mais, as mensagens são enviadas utilizando sendTo e recebidas utilizando recvFrom,
        como o objetivo é medir a taxa de perda de pacotes, não há reenvio de mensagens nem
        confirmação de recebimento:  
      </p>

      <div class="communication">
        <div class="imgWrapper serverSend">
          <img src="images/sendToClient.png" alt="envio para o cliente do server">
        </div>
        <div class="imgWrapper clientSend">
          <img src="images/sendtoServer.png" alt="envio do cliente para o server">
        </div>
        <div class="imgWrapper receive">
          <img src="images/receiveFromClient.png" alt="recebimento pelo servidor">
        </div>
      </div>
    </div>
    <div>
      <h2>3. Testes</h2>
      <p>
        Os testes feitos foram realizados com as máquias h29 e h30 do laboratório 1/2 do 
        Dinf, assim como nas máquinas pessoais dos integrantes do grupo.
      </p>
      <p>
        <br>
        Os testes constituem em uma bateria de comunicações com número fixo de clientes = 1
        e variação na quantidade de mensagens, além de uma segunda bateria de testes com
        diferentes quantidades de clientes e quantidade de mensagens por cliente fixa = 100. 
        Fizemos dessa maneira com o objetivo de sermos exaustivos e não deixar dúvidas sobre
        os resultados.

        <br><br>
        Logs de execução e os arquivos fonte estão disponíveis abaixo. 
      </p>
    </div>
    <div>
      <h2>4. Resultados</h2>
      <p>
        Os resultados obtidos foram curiosos. A equipe percebeu que a comunicação entre duas
        máquinas diferentes e a comunicação nas máquinas pessoais dos integrantes do grupo
        não apresentaram resutados muito diferentes.
        <br><br>
        Apesar de a comunicação nas máquinas pessoais nem usar a placa de rede, notamos uma grande
        taxa de perda de pacotes quando o número de clientes era muito alto ou muitas mensagens
        estavam sendo enviadas por apenas um cliente. O mesmo ocorreu nas máquinas do laboratório,
        levando o grupo a acreditar que o IP não é responsável pelas perdas, mas sim a saturação
        do buffer UDP.
        <br><br>
        Além disso, a dupla também notou que não houve entrega de mensagens fora de ordem, o que 
        pode ser explicado pela curta distância e portanto baixa quantidade de hops entre as máquinas.
      </p>
      <p>
        <br>
        Agora, deixando as similaridades de lado, vamos a discussão dos resultados obtidos nas
        máquinas do laboratório.
      </p>

      <h3>4.1. Extração</h3>
      <p>
        Tanto cliente quanto servidor apresentam relatórios básicos de execução. Os clientes mostram
        quantas mensagens enviaram e indicam se tudo ocorreu como esperado, ao passo que o servidor
        mostra as taxas de perda de pacotes, quantas mensagens foram recebidas por cada cliente e
        quantas mensagens foram recebidas fora de ordem. Abaixo temos um exemplo dos relatórios
        básicos em tela para uma comunicação entre 3 clientes e 1 servidor com 5 mensagens por cliente:   
      </p>

      <div class="serverImages">
        <div class="imgWrapper">
          <img src="images/h29basic.png"  alt="relatório básico do cliente">
        </div>
        <div class="imgWrapper">
          <img src="images/h30basic.png" alt="relatório básico do servidor">
        </div>
      </div>

      <p>
        Agora um exemplo um pouco maior, com 8 clientes e 500 mensagens por cliente, porém mostrando 
        só o footer dos relatórios:
      </p>
      
      <div class="serverImages">
        <div class="imgWrapper">
          <img src="images/h29footer.png" alt="relatório extendido do cliente">
        </div>
        <div class="imgWrapper">
          <img src="images/h30footer.png" alt="relatório extendido do servidor">
        </div>
      </div>
      
      <p>
        <br>
        Além disso, o servidor também escreve alguns arquivos que são utilizados para geração de 
        gráficos e análise dos resultados obtidos. Esses arquivos contém informações sobre
        toda a bateria de testes realizada, permitindo uma análise mais geral dos resultados e podem 
        ser encontrados na aba de arquivos fonte.
      </p>

      <h3>4.2. Número de clientes fixo = 1</h3>
      <p>
        A primeira bateria de testes foi feita com um número fixo de clientes = 1 e variação na 
        quantidade de mensagens. O objetivo era verificar se a taxa de perda de pacotes aumentava
        com o aumento da quantidade de mensagens. 
        <br><br>
        Rodamos com um cliente para um intervalo de 1000 a 4e+06:
        
      </p>

      <div class="imgWrapper">
        <img src="images/totalClients.png"  alt="input teste 1">
      </div>
      
      <p>
        O
        teste foi repetido 4 vezes e a média de perda de pacotes foi calculada cada vez e anotada 
        nos gráficos:
      </p>

      <div class="graphs">
          <img src="graphs/loss-rate-vs-total-messages1.png" alt="gráfico de 1 cliente 1">
          <img src="graphs/loss-rate-vs-total-messages2.png" alt="gráfico de 1 cliente 2">
          <img src="graphs/loss-rate-vs-total-messages3.png" alt="gráfico de 1 cliente 3">
          <img src="graphs/loss-rate-vs-total-messages4.png" alt="gráfico de 1 cliente 4">
      </div>

      <p>
        Com uma taxa média final de 35.40% de perda de pacotes, o grupo concluiu que a taxa se mantém
        num intervalo pouco variável a partir do momento que o número de mensagens é grande o suficiente para
        causar a saturação do buffer UDP e portanto só depende da velocidade com que o servidor consegue
        processar as mensagens com relação a velocidade que o cliente está enviando e não da quantidade de
        mensagens em si, ao menos quando temos apenas um cliente enviando mensagens. Isso é 
        ainda mais aparente quando notamos que em determinados momentos a taxa subiu ou desceu abruptamente,
        o que pode ser explicado pela carga que cada máquina estava suportando no momento, o que por sua vez 
        pode ter influenciado o tempo de processamento recebido pelos processos, mudando o balanço velocidade
        de envio / velocidade de recebimento.
      </p>

      <h3>4.3. Número de clientes variável</h3>
      <p>
        A segunda bateria de testes foi feita com um número de clientes variável em cima de um número
        fixo de mensagens = 100 por cliente. O objetivo era verificar como a taxa de perda seria afetada
        com a concorrência de mais clientes.
        <br><br>
        Rodamos com 100 mensagens por cliente para um intervalo de 10 a 10000 clientes, totalizando um 
        máximo de 1e+06 mensagens:
      </p>

      <div class="imgWrapper">
        <img src="images/totalMessages.png"  alt="input teste 2">
      </div>

      <p>
        Aqui vale a pena ressaltar que inicialmente queriamos rodar com até 40000 clientes, mas atingimos
        o limite de processos simultâneos nas máquinas do dinf e, por isso, diminúimos o intervalo.
        <br><br>
        Assim como no teste 1, repetimos o teste 4 vezes e anotamos a média de perda de pacotes de cada 
        rodada nos gráficos abaixo:
      </p>

      <div class="graphs">
        <img src="graphs/loss-rate-vs-total-clients-1.png" alt="gráfico de 1 cliente 1">
        <img src="graphs/loss-rate-vs-total-clients-2.png" alt="gráfico de 1 cliente 2">
        <img src="graphs/loss-rate-vs-total-clients-3.png" alt="gráfico de 1 cliente 3">
        <img src="graphs/loss-rate-vs-total-clients-4.png" alt="gráfico de 1 cliente 4">
      </div>

      <p>
        Aqui os resultados foram um pouco mais curiosos. Quando realizamos esse teste nas máquinas pessoais
        dos integrantes da equipe, obtivemos uma taxa de perda muito superior a taxa encontrada no teste 1, 
        quando o número de clientes era fixo = 1. Devido a isso, inicialmente acreditamos que algo similar
        aconteceria nas máquinas do laboratório, porém o contrário aconteceu, a taxa diminui drasticamente!
        <br><br>
        Após certa análise, acreditamos que o motivo para essa diferença reside na diferença da potência
        das CPUS utilizadas, em especial a quantidade de processos concorrentes que cada máquina suporta. 
        Nas máquinas pessoais, o número de processos concorrentes permitido pela CPU é muito maior que o 
        permitido pelas máquinas do laboratório, em especial a máquina h29. Além disso, a máquina h29
        (onde rodamos o cliente) tem caches de CPU menores e frequência de clock também menor que as 
        máquinas pessoais utilizadas:
      </p>

      <div class="serverImages">
        <div class="imgWrapper">
          <img src="images/arquiteturaH29.png"  alt="arquitetura h29">
        </div>
        <div class="imgWrapper">
          <img src="images/arquiteturaGlastheim.png"  alt="arquitetura pessoal">
        </div>
      </div>

      <p>
        Pelos relatórios de CPU acima, notamos que a máquina Glastheim (pessoal) tem quatro vezes
        mais CPUs que a máquina h29 (laboratório), o que impacta diretamente na quantidade de processos
        concorrentes permitidos.
        <br><br>
        Voltando aos gráficos, portanto, acreditamos que a diminuição na taxa de perda de pacotes se deve
        à baixa concorrência suportada pela máquina h29, o que faz com que o escalonador de tarefas e o tempo
        que cada processo passa dormindo afetem muito mais a taxa real de transmissão de pacotes, o que 
        dá mais tempo para o servidor processar as mensagens e diminui a taxa de perda.
        <br><br>
        No mais, com uma taxa média de perda final de 5.72% de perda de pacotes, chegamos a uma conclusão
        similar a do teste 1: como uma taxa de perda pouco variável, mais uma vez se torna evidente que
        a taxa depende mais da velocidade com que o servidor consegue processar as mensagens com relação a
        velocidade de envio dos clientes do que com a quantidade de mensagens sendo recebidas.
      </p>

      <h3>4.4. Conclusões</h3>
      <p>
        Como a taxa de perda de pacotes aparece e se mantém num intervalo pouco variável 
        a partir do momento em que a quantidade de mensagens chegando ao servidor é o 
        suficiente para sobrecarregar o buffer devido a relação velocidade de envio / velocidade de 
        recebimento (contamos aqui todo o processamento feito em cima das mensagens no servidor), a equipe 
        acredita que a taxa de perda está diretamente relacionada com a saturação do buffer UDP do servidor.
        <br><br>
        Além disso, devido ao baixo potencial de concorrência da máquina h29, a equipe decidiu que os 
        resultados do teste 1 são mais confiáveis para determinar a taxa média de perda de pacotes
        da rede, o que então nos deixa com uma <b>taxa média aproximada de 35.40%</b> de perda de pacotes.
        <br><br>
        No mais, vale a pena lembrar que não tivemos pacotes fora de ordem em nenhum dos testes, tanto locais
        quanto no laboratório, fato que o grupo atribui ao pequeno número de hops entre as máquinas utilizadas.
        <br><br>
        Por fim, a equipe acredita ter cumprido com os requisitos do trabalho, tendo realizado testes
        exaustivos e com resultados consistentes para atingir os resultados desejados.
      </p>
    </div>
    
    <div>
      <h2>5. Arquivos</h2>  
      
      <h3>5.1. Fonte</h3>
      <div class="fontes">
        <a href="./fontes/Makefile.txt">Makefile</a>
        <a href="./fontes/client.cpp.txt">client.cpp</a>
        <a href="./fontes/client.h.txt">client.h</a>
        <a href="./fontes/main-client.cpp.txt">main-client.cpp</a>
        <a href="./fontes/server.cpp.txt">server.cpp</a>
        <a href="./fontes/server.h.txt">server.h</a>
        <a href="./fontes/server-main.cpp.txt">server-main.cpp</a>
        <a href="./fontes/message.cpp.txt">message.cpp</a>
        <a href="./fontes/message.h.txt">message.h</a>
      </div>

      <h3>5.2. Relatórios gerais</h3>
      <p>
        Os relatórios gerais foram utilizados para gerar os gráficos acima. O servidor é responsável
        por montar esses arquivos a partir dos logs extraídos da comunicação cliente/servidor. A nomenclatura
        aqui segue o padrão general-report-[num rodada].txt e que os relatórios são arquivos csv com o seguinte
        header: "totalClients, totalMessages, totalMessagesLost, lossRate"
      </p>
      <div id="report" class="report">
        <div>
          <h5>Teste 1</h5>
          <div id="report1" class="report">
          </div>
        </div>
        <div>
          <h5>Teste 2</h5>
          <div id="report2" class="report">
          </div>
        </div>
      </div>

      <h3>5.3. Logs</h3> 
      <p>
        Aqui temos os logs de cada comunicação realizada nos testes. Como demonstrado nos exemplos acima, o 
        relatório de perda é impresso no fim do log do servidor. Ali, pode-se encontrar claramente
        perda de pacotes entre a comunicação, como por exemplo no fim do log server-1-1000-1.txt:
      </p>
      <div class="imgWrapper">
        <img src="images/perdaPacotes.png" alt="log">
      </div>
      <p>
        Além disso, aqui vale destacar que a nomenclatura dos arquivos segue o padrão 
        [cliente/servidor]-[qtd clientes]-[qtd mensagens por cliente]-[num da rodada].txt
        <br><br>
        No mais, não colocamos os logs para o teste 1 para 4000000 de mensagens visto que, mesmo compactados,
        eram muito grande e o github não aceitava o upload.
        <br><br>
      </p>
      <h4>5.3.1. Teste 1</h4>
      <div id="teste1" class="teste1">
        <div>
          <h5>Logs do cliente</h5>
          <div id="clientLogs1" class="logs">
          </div>
        </div>
        <div>
          <h5>Logs do servidor</h5>
          <div id="serverLogs1" class="logs">
          </div>
        </div>
      </div>

      <h4>5.3.2. Teste 2</h4>
      <div id="teste1" class="teste1">
        <div>
          <h5>Logs do cliente</h5>
          <div id="clientLogs2" class="logs">
          </div>
        </div>
        <div>
          <h5>Logs do servidor</h5>
          <div id="serverLogs2" class="logs">
          </div>
        </div>
      </div>
    </div>
  </section>
</body>
</html>